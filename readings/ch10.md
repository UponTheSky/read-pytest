- mock?: used to swap out pieces of the system to isolate bits of our application code
  from the rest of the system

- mock object = test double = spy = fake = stub
- may be used with `monkeypatch` fixture

# Isolating the Command-Line Interface
- for testing a module(unit testing), we need to isolate the module's logic and cut off access to the rest of the system

# Testing with Typer
- `typer.testing.CliRunner`: no need of `subprocess.run` in order to test a cli application

# Mocking an Attribute
- how to mock an attribute of a class/module?: `mock.patch.object`
- the call to `mock.patch.object` used as a context manager within a `with` block returns a mock object that is cleaned up after the `with` block

```py
from unittest import mock

with mock.patch.object(cards, '__version__', '1.2.3.'):
  # do the testing you want...
```

- why mocking?
  - mock object replaces part of our system
  - setting attribute values, return values for callables, or looking at how callables are called

# Mocking a Class and Methods
- you can mock a class in a module
  - if that mocked class is called, a new mock object is returned("return_value" attribute of the original mocked object)

- modifying the return value:

```py
with mock.patch.object(cards, "CardsDB") as MockCardsDB:
    MockCardsDB.return_value.path.return_value = '/foo/'
    # MockCardsDB.return_value => mocked instance
    # return_value.path => the path method of this mocked instance
    # path.return_value => the mocked return value of the path method
```

- making it as a fixture
```py
@pytest.fixture
def mock_cardsdb():
  with mock.patch.object(cards, "CardsDB", autospec=True) as CardsDB:
    yield CardsDB.return_value
```

# Keeping Mock and Implementation in Sync with Autospec
- problem: mock object is too flexible => can accept any arguments, number of arguments, etc.
- *mock drift*: when the interface you are mocking changes, and your mock in your test code doesn't
  - misspelling a method
  - adding/removing parameters
  - changing a method name during refactoring
- `autospec=True`: the mock imitates the interface of the mocked object
  - recommendation: always autospec whenever you can

# Making Sure Functions Are Called Correctly
- sometimes we don't really care about what the return values are 
  - we only care about whether they're called correctly or not
  - also, what if that method doesn't return at all?

```py
mock.cardsdb.add_cards.assert_called_with(expected)
```
- read: https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called
  - `assert_called`
  - `assert_called_once`
  - `assert_called_with`
  - a lot others

# Creating Error Conditions
- want to make sure that our function handles any exceptions well
- `side_effect`

```py
mock_cardsdb.delete_card.side_effect = cards.api.InvalidCardId
```

## remark: Mocking Tests Implementation, Not Behavior
- testing implementation: heavily dependent on changes in the code
  - will break when even a simple refactoring has been made
  - avoid *change detector tests*

# Testing at Multiple Layers to Avoid Mocking
- how to avoid mocking?: mocking is innately for testing implementations, rather than behaviors
- mixed-layer approach: why not just calling the APIs themselves?
  - implement APIs solely for testing and debugging
  - testing behavior rather than implementation

# Using Plugins to Assist Mocking
- `pytest-mock`: an wrapper of `unittest.mock`
  - benefit: automatically cleans up the fixture => no need of `with` clause

- other mocking plugins for: databases, http servers, requests
